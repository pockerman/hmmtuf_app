\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{ifpdf,newtxtext,newtxmath} 
\usepackage{array,graphicx,dcolumn,multirow,hevea,abstract,hanging,fancyhdr,float}
\usepackage{subfigure}
% change next 3 lines each issue
\newcommand{\jref}{http://journal.sjdm.org/vol16.1.html}
\newcommand{\jhead}{} %Judgment and Decision Making, Vol.~16, No.~1}
\newcommand{\jdate}{} %{January 2021}
\topmargin=-.3in \oddsidemargin=.3in \evensidemargin=.3in \textheight=9in \textwidth=6in
\pagestyle{fancy} 
\fancyhead[L]{\protect\small \href{\jref}{\jhead}, \jdate}
\fancyhead[R]{} %{\protect\small SHORT TITLE} % replace with running head
\fancypagestyle{firstpage}{%
 \lhead{\protect\small \href{\jref}{\jhead}, \jdate}
 \rhead{}
}
\usepackage[labelfont=sc,textfont=sf]{caption}
\usepackage[hyperfootnotes=false,breaklinks=true]{hyperref} % was dvipdfmx
% \usepackage[hyperfootnotes=false,breaklinks=true,linkbordercolor={1 1 1},citebordercolor={1 1 1}]{hyperref}
% \usepackage{natbib} % must come afer hyperfootnotes, use 2nd version for bibtex
% \setlength{\bibsep}{0pt}
\urlstyle{rm}
\usepackage[hyphenbreaks]{breakurl}
% DO NOT USE ADDITIONAL PACKAGES unless you make sure they work with Hevea.
% You may define new commands, but these may cause other troubles, so try to avoid it.

% FOR BIBTEX USERS (Bibtex is not recommended, but we can use it):
% \usepackage{natbib} % must come afer hypperref
% in references: \bibliographystyle{apalike3} \setlength{\bibsep}{0pt} \bibliography{WHATEVER}
% download http://journal.sjdm.org/apalike3.bst
\usepackage{booktabs} % \toprule \midrule \bottomrule \cmidrule(lr){a-b}
\graphicspath{{imgs/} }
% define centered and ragged columns:
\newcolumntype{L}[1]{>{\raggedright\arraybackslash }p{#1}} % can use m{}
\newcolumntype{C}[1]{>{\centering\arraybackslash }p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash }p{#1}}
\newcolumntype{d}[1]{D{.}{.}{#1}} % d{3.2} for 3 places on l, 2 on r
\newcommand{\mc}{\multicolumn}
\setlength\tabcolsep{1mm}
\setlength\columnsep{5mm}
\setlength\abovecaptionskip{1ex}
\setlength\belowcaptionskip{.5ex}
\setlength\belowbottomsep{.3ex}
\setlength\lightrulewidth{.04em}
\renewcommand\arraystretch{1.2}
\renewcommand{\topfraction}{1}
\renewcommand{\textfraction}{0}
\renewcommand{\floatpagefraction}{.9}
% \renewcommand{\baselinestretch}{1.00} \large\normalsize % for fixing spaces
\widowpenalty=1000
\clubpenalty=1000
\setlength{\parskip}{0ex}
\let\tempone\itemize
\let\temptwo\enditemize
\let\tempthree\enumerate
\let\tempfour\endenumerate
\renewenvironment{itemize}{\tempone\setlength{\itemsep}{0pt}}{\temptwo}
\renewenvironment{enumerate}{\tempthree\setlength{\itemsep}{0pt}}{\tempfour}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{page}{1} % start with first page

\title{Thermodynamically ultra-fastened DNA regions mapping based on hidden Markov modeling}

\author{
Colin Veal\thanks{Department of Genetics and Genome Biology, University of Leicester, UK. Email: cdv1@leicester.ac.uk.}\;\,\thanks{Corresponding author.}
\and 
  Alexandros Giavaras \thanks{Department of Genetics and Genome Biology, University of Leicester, UK.} %and Anthony Brookes\thanks{Department of Genetics and Genome Biology, University of Leicester, UK.} 
%\and
 Anthony Brookes\thanks{Department of Genetics and Genome Biology, University of Leicester, UK.} %\footnotemark[2] % indicates same as 2nd thanks
}

\date{} % leave empty
\begin{document} % goes here

\begin{htmlonly}
\href{\jref}{\jhead}, \jdate, pp.\
\end{htmlonly}

\maketitle
\thispagestyle{firstpage}

\begin{abstract}

A mapping of thermodynamically ultra-fastened (TUF) DNA regions
based on a hidden Markov model (HMM) is discussed. Initial results indicate
that the developed HMM is capable of capturing the TUF regions formed
in the DNA strand. This is verified by visually assessing the 
Viterbi paths generated by the model.
%The abstract is a brief (usually one paragraph) summary
%of the whole paper, including the problem, the method for solving
%it (when not obvious), the results, and the conclusions suggested
%or drawn.  Do not write the abstract as a hasty
%afterthought. Look at it as a real exercise in cramming the most
%information in one paragraph.  The reader should not have to read
%any of the rest of the paper in order to understand the abstract
%fully.  Many readers will read only the abstract.  Other readers
%will use it to decide what to look for in the paper, or to decide
%whether to read the whole thing.  Remember 
%\href{http://en.wikipedia.org/wiki/The_Elements_of_Style}{Strunk \&
%  White's} admonition, ``Omit needless words.''

\smallskip
%\largeskip
\noindent
Keywords: Thermodynamically ultra-fastened, DNA, hidden Markov model, 
\end{abstract}

%{\renewcommand{\thefootnote}{}
%\footnotetext{ % note blank lines above and below acknowledgment

  %Portions of this template are shamelessly stolen from other
  %documents lying around on the author's computer. He is grateful to
  %Lenovo, Inc.

%Copyright: \copyright\ 2021.
%The authors license this article under the terms of the
%\href{http://creativecommons.org/licenses/by/3.0/}{Creative Commons
%  Attribution 3.0 License.}
%}}

%\saythanks

\setlength{\baselineskip}{16pt plus.2pt}

\section{Introduction}
\label{itro}

Thermodynamically ultra-fastened (TUF) regions are stretches of the DNA which fail to denature
even after the application of extreme melting conditions \cite{veal2012}. 
This behavior effectively reduces the amplification efficiency in these regions. It has been reported that TUF regions contain a core sequence which exhibits an increased GC concentration relative to the surrounding DNA. It is in fact these locally concentrated spikes of GC content which is believed to remain duplexed despite the application of denaturation processes \cite{veal2012}. 

Computational modelling and analysis of TUF regions requires the ability to somehow identify these regions in the 
DNA strand. However, to the best of our knowledge, such tools do not yet exist. Visually, identifying and
labeling TUF regions, although feasible, is time consuming and error prone to say the least. 

The aim of this work \footnote{The software developed under the present study can be found at \url{https://github.com/pockerman/hmmtuf_app}} is twofold; the development of a mathematical approach so that a mapping of TUF regions can be created and the analysis of the TUF core regions. Such a tool will allow the labeling of these regions so that these can identified and further analysed.  In this regard, we employ a hidden Markov modelling methodology. Concretely, our approach uses two sequences; a sequence that it underwent WGA treatment (sample  m605), and  one that was not treated (sample m585). This is necessary in order to amplify the existence of TUF regions. In whole genome amplified (WGA) read-depth sequencing samples, TUF regions are often represented as regions of low coverage, resembling deletions. This resemblance actually makes it very difficult to computationally distinguish with copy deletions.
%two assumes that in whole genome amplified (WGA) read-depth (RD) sequencing samples, TUF regions are often represented as regions of low coverage, resembling deletions.  
%that  from modelling copy number variation see for example \cite{Wang2007, cahan2008}.  Concretely, in whole genome amplified (WGA) read-depth (RD) sequencing samples, TUF regions are often represented as regions of low coverage, resembling deletions. 
Thus,  the developed HMM classifies segregated chromosome regions into states depending on their average read-depth count. 
Although the exact characteristics in terms of read-depth of such a state are not known, the assumption is that a low read-depth observed in a WGA sample in combination 
of a normal one observed in the same region for a non-WGA treated sample is indicative of TUF. Using this read-depth based characterization, we can distinguish commonly found behavior in sequences such single copy or full copy deletion. In terms of the HMM, the TUF regions can simply be modelled as an extra state. Once a characterization of the DNA regions is available in terms of TUF, we can further process these regions in order to understand their structure. 

The remaining of this work is organised as follows. Section \ref{hmm_general} briefly describes the general principles underlying  hidden Markov models. Concretely,  we focus on discrete and time invariant models. 
Section \ref{hmm_tuf} discusses the particularities of our approach towards establishing a hidden Markov model for TUF regions. Section \ref{tuf_core_analysis} discusses our efforts to understand the underlying nucleotide structure of TUF core regions.  Section \ref{results} presents some initial mappings extracted using the developed HMM.
Finally, section \ref{discussion}, presents a discussion on the developed methodology and indicates possible future work. 

\section{Hidden Markov model}
\label{hmm_general}

A hidden Markov model (HMM) is a probabilistic framework that uses two interrelated probabilistic mechanisms; a Markov chain of a finite
number of states, $N$, and a set of random functions each associated with a respective state \cite{koski}.  The set of discrete states is denoted by $S=\{S_0, S_1,\cdots, S_{N-1}\}$. At a given time instant, the 
system is assumed to be in some state and an observation is generated by the random function corresponding to this state  \cite{koski}.
State transitioning occurs according to a transition probability matrix  $\mathbf{A}$. Within  the HMM framework, an observer only sees the random output generated by the random functions corresponding to the states and not the states themselves. Thus, the state at which the system is in can only be probabilistically inferred. 

We use more or less standard notation and denote with $q_n \in S$ the state of the system under consideration at the discrete time instance $n$.  A sequence of states, each of which belongs in $S$, is denoted with $Q$; $Q=\{q_1q_2,\cdots q_T\}$. Moreover, a sequence of observations is denoted with $O$; $O=\{o_1o_2,\cdots o_T\}$. Overall, an HMM is characterized by the following parameters, see \cite{rabiner2009} and \cite{koski}

\begin{itemize}
	\item $\mathbf{A}$ a probability transition matrix
	\item $\mathbf{B}$ a probability emission matrix
	\item $\boldsymbol{\pi}$ an initialization vector
\end{itemize}
Each $a_{ij}$ of $\mathbf{A}$  expresses the probability of transitioning to state $j$ given that the previous state was $i$ namely

\begin{equation}
a_{ij} = P(q_n = j | q_{n-1} = i), \forall i,j \in S
\label{trans_prob_cond}
\end{equation}
Equation \ref{trans_prob_cond} expresses the assumption that the system states form a Markov chain \cite{rabiner2009}. In other words, the current system state depends only on the previous state.
Since the $a_{ij}$s represent probabilities, the following conditions should be respected \cite{koski}

\begin{equation}
a_{ij} \geq 0, \sum_{j} a_{i,j} = 1 
\end{equation}
Similarly, each element $b_{jk}$ of the emission matrix $\mathbf{B}$ specifies the probability that at time instant $n$ and state $j$, the observation is $o_k$ \cite{koski}:

\begin{equation}
b_{jk} = P(O_n = o_k | q_n = j)
\end{equation}
We have the following constraints for the $\mathbf{B}$ matrix
\begin{equation}
b_{jk} \geq 0, \sum_{k} b_{jk} = 1 
\label{emiss_prob_cond}
\end{equation}
An HMM does not require the number of states is the same as the number of observation symbols. 
Finally, the vector $\boldsymbol{\pi}$ provides the probability distributions at time $n=0$ meaning 

\begin{equation}
\pi_j(0) = P(q_0 = j)
\end{equation}
Collectively, we denote an HMM using the letter $\lambda$:

\begin{equation}
\lambda = (\mathbf{A}, \mathbf{B}, \boldsymbol{\pi})
\label{hmm}
\end{equation}
Finally, we assume that we are dealing with a time invariant system. In other words, the transition probability matrix remains constant \cite{rabiner2009} and \cite{koski}. 

Hidden Markov models have been used quite extensively in bioinformatics; copy number variation detection  \cite{coella2007},  \cite{Wang2007} and  \cite{cahan2008}, analysis of of of array CGH data \cite{fridlyand2004}, 
analysis of profile series \cite{Sschliep2003}. A general review of hidden Markov modelling in relation to bioinformatics is given, for example, in \cite{koski}. In this work, we develop a  hidden Markov model
in order to establish a mapping for thermodynamically ultra-fastened DNA regions. Out methodology  is described in the next section.


%A general review of HMM in relation to bioinformatics is given in \cite{koski}. Hidden Markov models have been used for copy number variation detection see for example. \cite{coella2007},  \cite{Wang2007} and  \cite{cahan2008}, the analysis of of array CGH data \cite{fridlyand2004}, and the analysis of profile series \cite{Sschliep2003}.

%In the next section, we develop a hidden Markov model in order to identify TUF regions. 

\section{Hidden Markov model for TUF regions} % example of a heading
\label{hmm_tuf}

In this section we describe a hidden Markov  model for mapping TUF regions.
We develop the model by using the pomegranate \footnote{\url{https://github.com/jmschrei/pomegranate}} Python library.
%Our intention is to investigate the applicability of hidden Markov models in terms of identifying TUF regions in the genome. 
%In this regard, we develop an HMM model using .
%This section discusses the current state of the approach we use. It further attempts to justify certain modeling choices that have been made. 
Our approach uses two sequences; a sequence that it underwent WGA treatment (sample  m605), and  one that was not treated (sample m585). This is necessary in order to amplify the existence of TUF regions.  
Figure \ref{wga_no_wga } shows a snapshot of the amplification in the WGA sample compared to  the non-treated one as these are viewed in the IGV browser \cite{2011Robinson}.

\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.23]{wga_no_wga.png}
	\end{center}
	\caption{m605 and m585 samples.}
	\label{wga_no_wga }
\end{figure}

The developed model assumes the following set of discrete states:

\begin{itemize}
	\item Deletion
	\item TUF
	\item Normal copy (two states see below)
	\item Duplication
	\item TufDup
	\item Gap
\end{itemize}

The Gap state  corresponds to the case where there is no base present in either of the sequences used. The TUF state assumes a low WGA sample mean when compared to normal sample mean for the non-WGA sample. However, this does not fully capture the spectrum of the data, see figure \ref{tuf_tufdup}.  Thus, we introduce the  TufDup state in order to represent data where the WGA sample mean is rather small whilst the non-WGA sample mean is large enough to assume that this is a Duplication state.

As mentioned in the previous section, a hidden Markov model assumes that the system in hand can be in a state from a specified set $S$. This set of states can be assumed a priori implying some knowledge of the data. Examples of this methodology are given in \cite{coella2007} and \cite{Wang2007}  where six states are used.  Another approach is to use a clustering technique in order to determine the optimal number e.g. \cite{fridlyand2004} and \cite{liu2017}. In the latter approach, each cluster is assumed to represent a state. Clusters being very similar under some metric can be merged together.  A recent short survey on clustering techniques can be found in \cite{2016Irani}. One advantage of the clustering approach is that it allows for an educated guess about the optimal number of states represented in the data. Furthermore, it allows for an estimation parameters of the distributions that the HMM framework requires rather than resorting to heuristic assumptions. However, clustering can be as good as the data allows to distinguish the various states assumed. For example, TUF and single copy deletion are states that, at least with the data used in this work, are difficult to differentiate. Frequently used states in CNV studies are full and single copy deletion, normal and duplication. In this work, we also assume the existence of TUF and  Gap states. 

After determining the states that will be used in the HMM,  we need to establish the appropriate probability distribution that best models each state in terms of emission probabilities. This, in general, seems to be more important than how one is modeling the transition probability matrix $\mathbf{A}$, \cite{rabiner2009}.  There is a variety of methods to achieve this. The simplest is to assume a priori a given probability mass function with given parameters. Another approach is to  use an estimation technique such as histograms, kernel estimation or clustering. 

In this work, we assume that the states follow a two dimensional Gaussian distribution. The exception to this is the Gap state where we use a uniform distribution. The empirical distributions that we compute when investigating the data, this is the mean read-depth count per window, suggest that this assumption  is not unreasonable. Figures  \ref{fig:image1}, \ref{fig:image2} and \ref{fig:image3} plot the empirical distributions of the mean read-depth count per window of the data that was used to establish the distributional parameters for full copy deletion, single copy deletion and duplication states. 


\begin{figure}[h]
	\begin{subfigure}{}
		\includegraphics[scale=0.45]{imgs/deletion_dist_wga.png}
		\includegraphics[scale=0.45]{imgs/deletion_dist_no_wga.png}	
	\end{subfigure}
	
	\caption{Full copy deletion histogram for WGA and non-WGA samples.  }
	\label{fig:image1}
\end{figure}


\begin{figure}[h]
	\begin{subfigure}{}
		\includegraphics[scale=0.45]{imgs/single_copy_deletion_dist_wga.png}
		\includegraphics[scale=0.45]{imgs/single_copy_deletion_dist_no_wga.png}	
	\end{subfigure}
	
	\caption{Single copy deletion histogram for WGA and non-WGA samples.  }
	\label{fig:image2}
\end{figure}


\begin{figure}[h]
	\begin{subfigure}{}
		\includegraphics[scale=0.45]{imgs/duplication_dist_wga.png}
		\includegraphics[scale=0.45]{imgs/duplication_dist_no_wga.png}	
	\end{subfigure}
	
	\caption{Duplication histogram for WGA and non-WGA samples.  }
	\label{fig:image3}
\end{figure}


We estimate the parameters for these Gaussian distributions as follows. We cluster by using using a Gaussian mixture model (GMM)   \footnote{We use the scikit-learn implementation. See \url{https://scikit-learn.org/stable/}  for more details.} \cite{flach2012}  a data set which contains manually identified portions of the DNA that match the assumed states . The data set corresponds to small regions from chromosome 1 that contain the states that the model assumes. These regions are then discretised into non-overlapping windows each of which has size 100 bases.  We calculate the read-depth count means for the two samples, i.e. WGA and non-WGA, and then apply a cutoff filter to exclude outliers. The filter is simply a threshold on the means. Hence, a window is assumed as an outlier if either $\mu_{WGA} > 140$ or $\mu_{NWGA} > 120$. Where $\mu_{WGA}$ is the mean for the WGA sample and $\mu_{NWGA}$ is the mean for the non-WGA sample. The ensuing windows, form the input for the GMM .  We also investigated more traditional approaches like K-Means and PAM. However, these techniques tend to create equally sized clusters. This is something  that we do not anticipate to be the case ( for example the Normal state is expected, in general, to dominate the data). A GMM approach allows for more flexibility on the shapes of the clusters whilst we can use the parameters of the ensued Gaussian distributions, i.e. $\mu_{WGA}, \mu_{NWGA}$ and   $\boldsymbol{\Sigma} = diag(\sigma_{WGA}^2, \sigma_{NWGA}^2)$ where $\sigma_{i}$ is the window standard  deviation for the WGA and non-WGA sample,  into the HMM model. In GMM clustering the hard cluster assignment of K-means, is changed into a soft one \cite{flach2012}. Note that the windows which have been identified to contain gaps are excluded from the clustering calculations however they are kept in the final model.
Figure \ref{gmm_clustering} shows the clustered data when using five clusters. Only four clusters are actually visible. The cluster that represented deletion was dropped in favor of the  red cluster in the figure. Moreover, the single copy deletion cluster was also dropped.  
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.520]{gmm_clustering.png}
	\end{center}
	\caption{GMM clustering with five clusters.}
	\label{gmm_clustering}
\end{figure}  
The yellow cluster is used to extract the parameters for the Duplication state whilst the pink and blue are used to model two different Normal states labelled as Normal-I and Normal-II.
The TUF state is represented as a mixture model with two components each of which is represented as a two dimensional Gaussian distribution. Each component is weighted using a coefficient of $1/2$.  Figure \ref{tuf_clustering} shows the clustering for identifying the properties of the TUF state. The green component shown in figure \ref{tuf_clustering} is used in order to initialize the TUF state.

\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.520]{tuf_clustering.png}
	\end{center}
	\caption{GMM clustering for TUF state with three clusters.}
	\label{tuf_clustering}
\end{figure}

In order to model the Gap state we assume that both components follow a uniform distribution $U(-999.5, -998.5)$. Our intention is to make this state to stand out from the rest so that the model is forced to  select this when a gap window is found (see section \ref{results}).
 
The TufGap state is introduced after calibrating the model on chromosome 1.   
This is necessary as it is difficult to identify representative data for every state. Calibration is done by applying  the model on various regions and extracting the Viterbi path. The resulting path is then visually evaluated by loading both the region samples and the path on the IGV browser \cite{2011Robinson}.  Figure \ref{calib_chr1} shows the predicted states for chromosome 1 and region $[1-20]\times 10^6$ using the non-calibrated HMM model. The red spikes correspond to TUF windows. Figure \ref{tuf_tufdup} shows the classification of the windows \footnote{The windows are represented by the WGA and NWGA means} achieved by the calibrated model on region $[1-20]\times 10^6$. The non-calibrated model did not include the TufDup state. This caused the purple dots to be classified as duplication (shown in green). 

\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.240]{calib_chr1.png}
	\end{center}
	\caption{Viterbi path classification of windows.}
	\label{calib_chr1}
\end{figure}

\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.520]{tuf_tufdup.png}
	\end{center}
	\caption{Viterbi path classification of windows for calibrated model.}
	\label{tuf_tufdup}
\end{figure}

The TufDup state is also modeled using a two-dimensional Gaussian distribution. The parameters for the distribution are evaluated based on  figure \ref{tuf_tufdup} as follows.
The WGA component of the two dimensional distribution is using the mean and variance from the
neighbouring TUF state i.e. black dots in figure \ref{tuf_tufdup}. The NWGA component uses $\mu_{NWGA}=85$ which roughly corresponds to the middle of the purple dots in figure \ref{tuf_tufdup}. The variance $\sigma_{NWGA}^2$ is set according to the formula \ref{equation_sigma_tufdup}

\begin{equation}
	\sigma_{NWGA}^2 = \sigma_{NWGA, TUF}^2 + 0.3 \sigma_{NWGAG}^2
	\label{equation_sigma_tufdup}
\end{equation} 

where $\sigma_{NWGA, TUF}^2$ is the variance of the non-WGA sample from the nearby TUF region and $\sigma_{NWGAG}^2$ is the variance of the non-WGA sample from the Duplication cluster i.e. green dots in figure \ref{tuf_tufdup}. Thus, we assign portion of the $\sigma_{NWGAG}$ to the variance of the non-WGA sample. The factor 0.3 was determined by plotting the contours of the two ensued distributions for TUF and TufDup and checked whether their contours mixed. We chose the parameter such that the two distributions barely mix with each other.

%We extract the purple dots and calculate the variances of the WGA and non-WGA samples. Let us  call these $\sigma_{WGAG}^2$ and $\sigma_{NWGAG}^2$. Then, we set $\mu_{WGA}$ and $\sigma_{WGA}^2$ equal to the mean from the neighboring TUF state whilst the $\mu_{NWGA}$ is set to 85.  The variance $\sigma_{NWGA}^2$  is set according to equation \ref{equation_sigma_tufdup}

%\begin{equation}
	%\sigma_{NWGA}^2 = \sigma_{NWGA, TUF}^2 + 0.3 \sigma_{NWGAG}^2
	%\label{equation_sigma_tufdup}
%\end{equation} 

%Thus, we assign portion of the $\sigma_{NWGA-GREEN}$ to the variance of the non-WGA sample. The factor 0.3 was determined by plotting the contours of the two ensued distributions for TUF and TufDup and checked whether their contours mixed. We chose the parameter such that the two distributions barely mix with each other. %This is shown in figure \ref{tufdup_creation}

%\begin{figure}[!htb]
%	\begin{center}
%		\includegraphics[scale=0.320]{tufdup_creation.png}
%	\end{center}
%	\caption{Viterbi path classification of windows for calibrated model.}
%	\label{tufdup_creation}
%\end{figure}

The HMM also requires as input the initialization vector $\boldsymbol{\pi}$ and the transition matrix $\mathbf{A}$, see equation \ref{hmm}. For the former we assume a uniform probability for every state i.e. every state is equally likely to initiate the sequence of hidden states. Hence, 

\begin{equation}
\pi_i = \frac{1}{|S|}, ~~ \forall i \in S
\end{equation}
where $|S|$ denotes the number of discrete states. For the latter,  we assume that every state can transition to any other state including itself. 
However, we assign a significantly higher probability to the latter
scenario than the former. In other words, we assume that the model is more likely to stay in a given state than transitioning to another. This is summarized in equation \ref{initial_A}

\begin{equation}
\mathbf{A} = \begin{bmatrix}0.85 & 0.025 & 0.025 & 0.025 & 0.025 & 0.025 & 0.025 \\ 

0.025 & 0.85 & 0.025 & 0.025 & 0.025 & 0.025 & 0.025 \\
0.025 & 0.85 & 0.85 & 0.025 & 0.025 & 0.025 & 0.025 \\
0.025 & 0.85 & 0.025 & 0.85 & 0.025 & 0.025 & 0.025 \\
0.025 & 0.85 & 0.025 & 0.025 & 0.85 & 0.025 & 0.025 \\
0.025 & 0.85 & 0.025 & 0.025 & 0.025 & 0.85 & 0.025 \\
0.025 & 0.85 & 0.025 & 0.025 & 0.025 & 0.025 & 0.85 
\end{bmatrix}
\label{initial_A}
\end{equation}

In summary, the used hidden Markov model is as follows

\begin{itemize}
	\item $\pi_i = \frac{1}{|S|}, ~~ \forall i \in S$
	\item Gap state $G\sim U(-999.5, -998.5)$
	\item TUF and TufDup states $\sim \sum_{i=1}^{2} c_i N(\boldsymbol{\mu}, \boldsymbol{\Sigma}), c_i = 1/2$
	\item Every other state $S \sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})$  
\end{itemize}
Figure \ref{hmm_figure}
shows the HMM model with the transition probabilities used in a graphical form.
We remark however, that the framework we use is flexible enough to assume different parametric models and add or remove states.

\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.260]{hmm.png}
	\end{center}
	\caption{States and transition probabilities for HMM model.}
	\label{hmm_figure}
\end{figure} 


\section{Towards TUF core analysis}
\label{tuf_core_analysis}
Once a characterization of the DNA sequence in terms of TUF regions is available, one can further question what is the underlying nucleotide structure of these TUF regions. In order to do so, we process the Viterbi paths using \emph{SPADE} \footnote{See \url{https://github.com/yachielab/SPADE} for details}.


This is a software for exploring periodic repeat regions from large genomic and protein data resources. \emph{SPADE} first extracts multiple sequence entries from an input file (GenBank or FASTA format) and identifies sequence type (DNA or protein) for each entry. Each sequence entry is scanned by a sliding window to count k-mers and highly repetitive regions are extracted. The sequence periodicity of each highly repetitive region is then evaluated based on position-period matrix that cumulatively plots distance between neighboring same k-mers and their sequence positions. The periodic sequence region is defined and the periodic sequence units are queried for a multiple alignment to identify repetitive motif and its sequence logo. The representative motif sequence is aligned back to the sequence of the periodically repeating region to annotate the repeating units. Finally, the annotations for detected periodic repeats are added to the input information and output in GenBank format with an option of visualizing k-mer density, position-periodicity matrix, sequence motif logo and repetitive unit loci with neighboring genes for each periodic repeat.

Once the core regions have been extracted we can apply distance as well as clustering methods in order to discover any underlying structures. Towards this direction, there are many distance functions that compute text similarity. Our tool uses the \emph{textdistance}\footnote{See \url{https://pypi.org/project/textdistance/} for more details. } Python library which has implementations for more than thirty text distance algorithms. Furthermore, we also implemented the approach described in \cite{2014Bao}. 

In this case, the nucleotide repeat string is cast in a twelve dimensional space. This is done by converting the repeat string into three strings according to the categories of nucleotide bases, and then yields a 12-dimension feature vector. The feature values are computed by an entropy based model that takes both local word frequency and position information into account \cite{2014Bao}. 

 
\section{Results}
\label{results}

This section presents some initial TUF region mappings as these are visualised on the IGV browser.
Concretely, we compute  the Viterbi paths for chromosomes 1, 2. 
The Viterbi path simply answers the following 
question \cite{rabiner2009}; given an HMM $\lambda$ and a sequence of observations $O$ we seek to find the state sequence  $Q$ that maximizes the probability 

\begin{equation}
P(Q|O, \lambda)
\end{equation}

We extract regions typically of size $20\times 10^6$ bases. The regions are 
discretised into non-overlapping  windows of size 100 bases. Each of the windows has a view of both samples, i.e. m605 and m585.  The same cutoff mean that is used previously is also applied.
This is the same approach we used in the previous section. However, in this section, Gap windows are included in the formed sequence. In the present context, the observations are pairs of RD means corresponding to the sample view that each window contains. The HMM model discussed in section \ref{hmm_tuf} is used to compute the Viterbi path for the sequence. Overall, we plot the mappings for the following regions for chromosomes 1 and 2 

\begin{itemize}
	\item $[1-20]\times 10^6$
	\item $[20-40]\times 10^6$
	\item $[40-60]\times 10^6$
	\item $[60-80]\times 10^6$
\end{itemize} 

Figures \ref{fig:rslt_image1}, \ref{fig:rslt_image2} present the classification of the windows after applying the Viterbi algorithm for chromosome 1. 
Figures \ref{fig:rslt_image3} and \ref{fig:rslt_image4} shows the mappings for these regions as these are visualised on the IGV browser \cite{2011Robinson}. The red stripes correspond to the TUF regions so that they are easier to distinguish. 

%Figures \ref{fig:rslt_image1} and \ref{fig:rslt_image2} show the labelling of the windows with respect to the their mean value for regions 1, 2, 3 and for 4 for chromosome 1.

\begin{figure}[!htb]
	\begin{subfigure}{}
		\includegraphics[scale=0.55]{chr1_region_1.png}
		\includegraphics[scale=0.55]{chr1_region_2.png}
	\end{subfigure}

	\caption{Regions 1 and 2 for chromosome 1. Left to right.  }
	\label{fig:rslt_image1}
\end{figure}

\begin{figure}[!htb]
	\begin{subfigure}{}
		\includegraphics[scale=0.55]{chr1_region_3.png}
		\includegraphics[scale=0.55]{chr1_region_4.png}	
	\end{subfigure}

	\caption{Regions 3 and 4  for chromosome 1. Left to right.  }
	\label{fig:rslt_image2}
\end{figure}

%Figures \ref{fig:rslt_image3} and \ref{fig:rslt_image4} shows the mappings for these regions as these are visualised on the IGV browser \cite{2011Robinson}. The red stripes correspond to the TUF regions so that they are easier to distinguish. 

\begin{figure}[!htb]
	\begin{subfigure}{}
		\includegraphics[scale=0.25]{chr1_1000000_20000000.png}
		\includegraphics[scale=0.25]{chr1_20000000_40000000.png}
	\end{subfigure}
	\caption{IGV mappings for regions 1 and 2  for chromosome 1.}
	\label{fig:rslt_image3}
\end{figure}

\begin{figure}[!htb]
	\begin{subfigure}{}
		\includegraphics[scale=0.25]{chr1_40000000_60000000.png}
		\includegraphics[scale=0.25]{chr1_60000000_80000000.png}
	\end{subfigure}
	\caption{IGV mappings for regions 3 and 4  for chromosome 1.  }
	\label{fig:rslt_image4}
\end{figure}

%\begin{figure}[h]
%	\begin{subfigure}{}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr1_region_5.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr1_region_6.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr1_region_7.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr1_region_8.png}	
%	\end{subfigure}
	
%	\caption{Regions 5,6,7,8  for chromosome 1 left to right.  }
%	\label{fig:image2}
%\end{figure}

%\begin{figure}[h]
%	\begin{subfigure}{}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr1_region_9.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr1_region_10.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr1_region_11.png}	
%	\end{subfigure}
	
%	\caption{Regions 9, 10, 11  for chromosome 1 left to right.  }
%	\label{fig:image3}
%\end{figure}

Similarly, figures \ref{fig:rslt_image5} and \ref{fig:rslt_image6} show the labelling of the windows with respect to the their mean value for regions 1, 2, 3 and for 4 for chromosome 2. Furthermore, figures \ref{fig:rslt_image7} and \ref{fig:rslt_image8} show the mapping of the regions in IGV browser.

\begin{figure}[h]
	\begin{subfigure}{}
		\includegraphics[scale=0.55]{chr2_region_1.png}
		\includegraphics[scale=0.55]{chr2_region_2.png}
	\end{subfigure}
	\caption{Regions 1 and  2 for chromosome 2. Left to right.}
	\label{fig:rslt_image5}
\end{figure}


\begin{figure}[h]
	\begin{subfigure}{}
		\includegraphics[scale=0.55]{chr2_region_3.png}
		\includegraphics[scale=0.55]{chr2_region_4.png}
	\end{subfigure}
	\caption{Regions 3 and 4  for chromosome 2. Left to right.}
	\label{fig:rslt_image6}
\end{figure}

\begin{figure}[!htb]
	\begin{subfigure}{}
		\includegraphics[scale=0.25]{chr2_1000000_20000000.png}
		\includegraphics[scale=0.25]{chr2_20000000_40000000.png}
	\end{subfigure}
	\caption{IGV mappings for regions 1 and 2  for chromosome 2.}
	\label{fig:rslt_image7}
\end{figure}

\begin{figure}[!htb]
	\begin{subfigure}{}
		\includegraphics[scale=0.25]{chr2_40000000_60000000.png}
		\includegraphics[scale=0.25]{chr2_60000000_80000000.png}
	\end{subfigure}
	\caption{IGV mappings for regions 3 and 4  for chromosome 2.}
	\label{fig:rslt_image8}
\end{figure}

%\begin{figure}[h]
%	\begin{subfigure}{}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr2_region_5.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr2_region_6.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr2_region_7.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr2_region_8.png}
%	\end{subfigure}
%	\caption{Regions 5, 6, 7, 8  for chromosome 2.}
%	\label{fig:image5}
%\end{figure}

%\begin{figure}[h]
%	\begin{subfigure}{}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr2_region_9.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr2_region_10.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr2_region_11.png}
%	\end{subfigure}
%	\caption{Regions 9, 10, 11  for chromosome 2.}
%	\label{fig:image6}
%\end{figure}

%\begin{figure}[h]
	
%	\begin{subfigure}{}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr6_region_1.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr6_region_2.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr6_region_3.png}
%		\includegraphics[scale=0.25]{dut11.eps}%{imgs/chr6_region_4.png}
%	\end{subfigure}
	
%	\caption{Regions 1 and 2,3,4  for chromosome 6.  }
%	\label{fig:image7}
%\end{figure}

Apart from region 1 for chromosome 1 the rest of the regions for both chromosomes are relatively uniform with respect to the mean RD count. This is illustrated both in the window labelling and in the IGV mapping. Note also that the GC count is shown somehow increased for region 1 of chromosome 1.  



\clearpage

%Use subsections and subsubsections etc. freely.

\section{Discussion}
\label{discussion}

In this work, we describe the development of a hidden Markov model in order to map  is described in order to map thermodynamically ultra-fastened DNA regions. These  are stretches of the DNA which fail to denature even after the application of extreme melting conditions. The model uses two DNA sequences and assumes seven different states. Some early mappings are reported in order to show case the utilization of the approach. We have, so far, developed a tool where the user can import hidden Markov models and export Viterbi paths so given DNA sequences. Furthermore, the user can also request for the extraction of TUF core repeats. 

Future work should include extensive validation of the model. This however may require a meticulous labelling of DNA regions. Once the model is validated, one  can use it to extract the identified TUF regions and further investigate or model their structure. 


\clearpage
%\subsection{How to add Lists}

%You can make lists with automatic numbering \dots

%\begin{enumerate}
%\item Like this,
%\item and like this.
%\end{enumerate}
%\dots or bullet points \dots
%\begin{itemize}
%\item Like this,
%\item and like this.
%\end{itemize}

%References should be in APA style. Examples are below.

\bibliography{references.bib}
\bibliographystyle{plain}

% FOR BIBTEX USERS INSTEAD OF REFERENCES SECTION
%\bibliographystyle{apalike3}
%\bibliography{bibliography.bib}
% OR CAN ALSO INCLUDE THE BBL FILE AFTER THE NEXT LINE, INSTEAD OF THE LAST LINE
%\section*{References}

%\begin{hangparas}{1em}{1}

  %Aarts, H., \& Dijksterhuis, A. (1999).  How often did I do it?
  %Experienced ease of retrieval and frequency estimates of past
  %behavior.  \textit{Acta Psychologica, 103}(3), 77--89. \url{http://someurl.html}.

  %Barberis, N. \& Thaler, R. (2003). A survey of behavioral finance.
  %In G. M. Constantinides, M. Harris \& R. Stultz (Eds.),
  %\textit{Handbook of the Economics of Finance,} pp.\ 1053--1123.
  %Elsevier Science, North Holland, Amsterdam

%\vfill % use this for column breaks
%\break

%Grice, H. P. (1975).  Logic and conversation. In P. Cole \& J.
%L. Morgan, (Eds.), \textit{Speech Acts}, pp.\ 41--58. London: Academic
%Press. \url{http://dx.doi.org/3.14159--1x}.
%\end{hangparas}

%\bigskip
%\section*{Appendix}

%The asterisk means that these divisions are not numbered.

%\subsection*{How to write Mathematics}

%This section is completely redundant with the text. Do not do
%that. This is just an example.

%\LaTeX{} is great at typesetting mathematics. Let $X_1, X_2, \ldots, X_n$ be a sequence of independent and identically distributed random variables with $\text{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$, and let
%\[S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}
%      = \frac{1}{n}\sum_{i}^{n} X_i\]
%denote their mean. Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n - \mu)$ %converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$.


%\subsection*{How to create Sections and Subsections}

%Use section and subsections to organize your document. Simply use the section and subsection buttons in the toolbar to create them, and we'll handle all the formatting and numbering automatically.

\end{document}

